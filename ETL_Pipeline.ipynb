{"cells":[{"cell_type":"markdown","source":["## Scientific Publications Data Warehouse\n\nProject 1: A Data Cube on top of Delta Lake (ETL)\n#### *Purpose*\nThe purpose is to extract data about scientific publications from JSON data that describe, title, topic, authors, etc., about a large number of papers and populate a data warehouse to issue analytics queries using SQL.\n\nWe will use Spark DataFrames to extract and transform the data.\n\nWe will also use Spark tables (delta tables) to be used for dimensions and fact tables as will be shown below.\n\n### *DWH Schema*\n\nWe will follow the proposed schema as shown:\n\nDBLP Fact Table:\n    - Date_ID (FK)\n    - Keyword_ID (FK)\n    - Type_ID (FK)\n    - Publication_ID (FK)\n    - Venue_ID (FK)\n    - FOS_ID (FK)\n    - ORG_ID (FK)\n    - Author_ID (FK)\n    - Lange_ID (FK)\n    - AuthorRank\n\nKeyword Table:\n    - ID\n    - Text\n\nType Table:\n    - ID\n    - Description\n\nPublication Table:\n    - ID\n    - Title\n    - Year\n    - PageStart\n    - PageEnd\n    - DOI\n    - PDF\n    - URL\n    - Abstract\n    - IndexedAbstract\n    - N_Citation\n\nVenue Table:\n    - ID\n    - Name\n    - City\n    - Country\n\nDate Table:\n    - ID\n    - Year\n    - Month\n    - Day\n\nLanguage Table:\n    - ID\n    - Name\n\nFOS Table:\n    - ID\n    - Field\n\nORG Table:\n    - ID\n    - Name\n    - City\n    - Country\n\nAuthor Table:\n    - ID\n    - FirstName\n    - LastName\n    - MiddleName\n\n\n### *Dataset*\n\nThe data source is https://www.aminer.org/citation, version 13, as it is the most detailed one in JSON\nformat. You can also check the schema of the respective data set on the same page under the  \"Description\" link – note that the schema may not correspond to the schema in the JSON file.\n\n\n#### Dataschema of V13\n\n_Backed to v11 schema, where id and references are in String form._*\n\n\n| --- | --- | --- | ---\n| Field Name | Field Type | Description | Example\n| id | string | paper ID | 43e17f5b20f7dfbc07e8ac6e\n| title | string | paper title | Data mining: concepts and techniques\n| authors.name | string | author name | Jiawei Han\n| authors.org | string | author affiliation | Department of Computer Science, University of Illinois at Urbana-Champaign\n| authors.id | string | author ID | 53f42f36dabfaedce54dcd0c\n| venue.id | string | paper venue ID | 53e17f5b20f7dfbc07e8ac6e\n| venue.raw | string | paper venue name | Inteligencia Artificial, Revista Iberoamericana de Inteligencia Artificial\n| year | int | published year | 2000\n| keywords | list of strings | keywords | [\"data mining\", \"structured data\", \"world wide web\", \"social network\", \"relational data\"]\n| fos.name | string | paper fields of study | Web mining\n| fos.w | float | fields of study weight | 0.659690857\n| references | list of strings | paper references | [\"4909282\", \"16018031\", \"16159250\",  \"19838944\", ...]\n| n_citation | int | citation number | 40829\n| page_start | string | page start | 11\n| page_end | string | page end | 18\n| doc_type | string | paper type: journal, book title... | book\n| lang | string | detected language | en\n| publisher | string | publisher | Elsevier\n| volume | string | volume | 10\n| issue | string | issue | 29\n| issn | string | issn | 0020-7136\n| isbn | string | isbn | 1-55860-489-8\n| doi | string | doi | 10.4114/ia.v10i29.873\n| pdf | string | pdf URL | //static.aminer.org/upload/pdf/1254/ 370/239/53e9ab9eb7602d970354a97e.pdf\n| url | list | external links | [\"http://dx.doi.org/10.4114/ia.v10i29.873\", \"http://polar.lsi.uned.es/revista/index.php/ia/ article/view/479\"]\n| abstract | string | abstract | Our ability to generate...\n| indexed_abstract | dict | indexed abstract | {\"IndexLength\": 164, \"InvertedIndex\": {\"Our\": [0], \"ability\": [1], \"to\": [2, 7, ...]}}"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"76c32f7e-8910-43be-b9a9-4bc0fb66b89a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Extract"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"239435bb-d8cf-4f1f-8f68-f0fece00ef2d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# let's fetch the data\n# !wget https://originalstatic.aminer.cn/misc/dblp.v13.7z\n# !7z x dblp.v13.7z\n"],"metadata":{"ExecuteTime":{"end_time":"2023-04-20T09:29:12.122802500Z","start_time":"2023-04-20T09:21:31.099174Z"},"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1beeeda5-b3ad-4c85-ad14-5e248e7e6ef4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%pip install gender_guesser"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f6b11b9a-290f-4135-b6a8-3036fba0c2e3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Python interpreter will be restarted.\nCollecting gender_guesser\n  Downloading gender_guesser-0.4.0-py2.py3-none-any.whl (379 kB)\nInstalling collected packages: gender-guesser\nSuccessfully installed gender-guesser-0.4.0\nPython interpreter will be restarted.\n"]}],"execution_count":0},{"cell_type":"code","source":["# we will read and process the data while cleaning it simultaneously\n\nimport json\nimport ast\nimport os\n# import tqdm.notebook\n\ndef process_json(file_name, split_size, output_prefix, offset=0, file_number=0):\n    with open(file_name, 'r', encoding='utf-8') as ifh:\n        # seek to the second line in the file\n        if offset > 0:\n            ifh.seek(offset)\n        else:\n            ifh.seek(1) # skip the first '['\n        file_number = file_number\n        checkpoint = []\n        file_sizes = []\n        end_of_file = False\n        # we will keep looping until all the lines are read\n        while not ifh or not end_of_file:\n            file_number += 1\n            # json_objects = [ast.literal_eval(build_json_object(ifh)) for _ in tqdm.notebook.tqdm(range(split_size))]\n            json_objects = []\n            while len(json_objects) < split_size:\n                try:\n                    json_objects.append(ast.literal_eval(build_json_object(ifh)))\n                except:\n                    end_of_file = True\n                    break # we reached the end of the file\n            print(f\"Checkpoint {file_number}: {ifh.tell()}, objects processed: {len(json_objects)}\")\n            # write each json object to a file\n            with open(f\"{output_prefix}{file_number}.json\", 'w', encoding='utf-8') as ofh:\n                # this process yields smaller files than using json.dump w/ indent = 4\n                for i, json_object in enumerate(json_objects):\n                    if i == len(json_objects) - 1:\n                        ofh.write(json.dumps(json_object) + \"]\")\n                    elif i == 0:\n                        ofh.write('[' + json.dumps(json_object) + \",\")\n                    else:\n                        ofh.write(json.dumps(json_object[0]) + \",\")\n            # get the size of the file\n            file_sizes.append(os.path.getsize(f\"{output_prefix}{file_number}.json\") / 1024 / 1024)\n            checkpoint.append(ifh.tell())\n            print(f\"Checkpoint {file_number}: {checkpoint[-1]}, objects processed: {len(json_objects)}, size of file {file_number}: {file_sizes[-1]} MB\")\n            # break # for testing purposes\n        print(f\"Finished processing {file_name}, {file_number} files created.\")\n        return checkpoint, file_sizes\n\ndef clean_line(line):\n    if \"NumberInt\" in line:\n        line = line.replace(\"NumberInt\", \"\") # NumberInt(123) -> (123)\n        line = line.replace(\"(\", '\"') # (123) -> \"123)\n        line = line.replace(\")\", '\"') # \"123) -> \"123\"\n    if \": null,\" in line or \": null\" in line:\n        line = line.replace(\"null\", '\"\"')\n    return line\n\ndef build_json_object(fh):\n    buffer = ''\n    line = fh.readline()\n    while line != \"},\\n\":\n        if not line:\n            print(\"Reached end of file\")\n            return buffer[:-2]\n        buffer += clean_line(line)\n        line = fh.readline()\n    buffer += line\n    return buffer\n"],"metadata":{"ExecuteTime":{"end_time":"2023-04-20T12:42:53.330663200Z","start_time":"2023-04-20T12:42:53.315020600Z"},"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"069dc17f-a320-4e6c-b083-41f466a4198b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# results = process_json('dblpv13.json', 100000, 'clean_dataset/dblpv13_clean_', offset=17260419910, file_number=53)\n# results = process_json('dblpv13.json', 100000, 'clean_dataset/dblpv13_clean_')"],"metadata":{"ExecuteTime":{"end_time":"2023-04-20T12:43:04.883874700Z","start_time":"2023-04-20T12:42:54.068889100Z"},"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"64fa077e-9846-4a0d-8bc0-cea5c87845d2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Transform\n\nHere we will begin the transformation part of our pipeline. We will use delta tables and pyspark dataframes to do this. There are a few tasks that we must complete:\n1. Drop publications with very short titles (one word, empty authors, etc.)\n2. Visualize the number of citations\n3. ISSN is sometimes filled with wrong values, we can either drop or make an effor to resolve using DOI for instance.\n4. Defining the type of publication (journal, book, conference, etc.)\n5. Resolving ambiguous author names\n6. Resolving ambiguous or abbreviated conference and journal names using DBLP database.\n7. Refining venues\n8. Author gender\n9. H-index of authors\n10. Normalization of the field of study"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"807e4833-98c2-48a3-ba74-034527a416c9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n"],"metadata":{"ExecuteTime":{"end_time":"2023-04-20T16:59:48.137747800Z","start_time":"2023-04-20T16:59:47.317942600Z"},"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3c3ae5fa-1a3d-48aa-9003-03995af3392d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["path_to_data = 'dbfs:/FileStore/tables/dblpv13_cleanv2_'\n# path_to_data = 'dbfs:/FileStore/tables/small_'"],"metadata":{"ExecuteTime":{"end_time":"2023-04-20T16:59:48.139617Z","start_time":"2023-04-20T16:59:48.126317200Z"},"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7b12b87c-097a-4839-a0eb-69a88003815d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# change the memory size depending\nspark = SparkSession.builder \\\n    .appName(\"Project1\") \\\n    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.1.0\") \\\n    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n    .config(\"spark.sql.warehouse.dir\", \"file:///tmp/spark-warehouse\")\\\n    .config(\"spark.driver.memory\", \"16g\")\\\n    .config(\"spark.executor.memory\", \"16g\")\\\n    .config(\"spark.driver.maxResultSize\", \"16g\")\\\n    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n    .getOrCreate()"],"metadata":{"ExecuteTime":{"end_time":"2023-04-20T17:00:14.267386800Z","start_time":"2023-04-20T16:59:50.977403700Z"},"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"20b6aeba-eed3-4c71-a601-479fb035ada9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# gender\n# %pip install gender_guesser\nimport gender_guesser.detector as gender\n\ndef get_author_gender(first_name):\n    d = gender.Detector()\n    gender_result = d.get_gender(first_name)\n    if gender_result == \"mostly_male\":\n        return \"male\"\n    elif gender_result == \"mostly_female\":\n        return \"female\"\n    else:\n        return gender_result\n\n# with api / has limit\n# import request\n# def get_author_gender(first_name):\n#     url = f'https://api.genderize.io/?name={first_name}'\n#     response = requests.get(url)\n#     if response.status_code == 200:\n#         data = response.json()\n#         if 'gender' in data:\n#             return data['gender']\n#     return None\n\ndef add_author_gender(authors):\n    genders = []\n    for author in authors:\n        print(author)\n        gender = get_author_gender(author.split()[0])\n        genders.append(gender)\n    return genders\n  \n# res_authors = [\"Álvaro Gonzalo-Ayuso\", \"Jesús Pérez\"]\n# res_authors = [\"Xiaohui Tan\", \"Pengcheng Fan\", \"Liming Luo\", \"Mingquan Zhou\"]\n# add_author_gender(res_authors)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"d7a3f3e4-fa78-4ae1-ab6a-b36d33c4e8c9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# author names\nimport requests\n\ndef resolve_names(name):\n    response = requests.get(\"https://dblp.org/search/author/api\", params={\"q\": name, \"format\": \"json\"})\n    if response.status_code == 200:\n        result = response.json()\n        if \"result\" in result and \"hits\" in result[\"result\"]:\n            if \"hit\" in result[\"result\"][\"hits\"]:\n                for hit in result[\"result\"][\"hits\"]:\n                    if \"info\" in hit and \"author\" in hit[\"info\"]:\n                        author_name = hit[\"info\"][\"author\"]\n#                     if author_name.lower() == name.lower():\n                        return author_name\n    return name\n\n\ndef add_resolved_names(authors):\n    names = []\n    for author in authors:\n        name = resolve_names(author['name'])\n        names.append(name)\n    return names\n\n# authors = [{\"_id\": \"53f43184dabfaedf4354af59\", \"bio\": \"null\", \"email\": \"mkhojast@bccrc.ca\", \"gid\": \"5b86c4a8e1cd8e14a3b0a117\", \"name\": \"Mehrnoush Khojasteh\", \"name_zh\": \"null\", \"oid\": \"null\", \"oid_zh\": \"null\", \"orcid\": \"null\", \"org\": \"British Columbia Cancer Research Centre, Vancouver, BC, Canada|Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada\", \"org_zh\": \"null\", \"orgid\": \"5f71b28e1c455f439fe3cad2\", \"orgs\": \"null\", \"orgs_zh\": \"null\", \"sid\": \"null\"}, {\"_id\": \"548a7e4ddabfaed7b5fa41f6\", \"bio\": \"null\", \"email\": \"wanlam@bccrc.ca\", \"gid\": \"5b8690dee1cd8e14a34ed9ef\", \"name\": \"Wan L Lam\", \"name_zh\": \"null\", \"oid\": \"null\", \"oid_zh\": \"null\", \"orcid\": \"null\", \"org\": \"British Columbia Cancer Research Centre, Vancouver, BC, Canada\", \"org_zh\": \"null\", \"orgid\": \"null\", \"orgs\": \"null\", \"orgs_zh\": \"null\", \"sid\": \"null\"}, {\"_id\": \"54480291dabfae87b7dc1fa9\", \"bio\": \"null\", \"email\": \"rababw@ece.ubc.ca\", \"gid\": \"5b86c1e5e1cd8e14a39d1258\", \"name\": \"Rabab K Ward\", \"name_zh\": \"null\", \"oid\": \"null\", \"oid_zh\": \"null\", \"orcid\": \"null\", \"org\": \"Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada\", \"org_zh\": \"null\", \"orgid\": \"5f71b28e1c455f439fe3cad2\", \"orgs\": \"null\", \"orgs_zh\": \"null\", \"sid\": \"null\"}, {\"_id\": \"54311531dabfae8f2912ab95\", \"bio\": \"null\", \"email\": \"cmacaula@bccrc.ca\", \"gid\": \"5b8690dee1cd8e14a34ed9ef\", \"name\": \"Calum MacAulay\", \"name_zh\": \"null\", \"oid\": \"null\", \"oid_zh\": \"null\", \"orcid\": \"0000-0003-4440-2792\", \"org\": \"British Columbia Cancer Research Centre, Vancouver, BC, Canada\", \"org_zh\": \"null\", \"orgid\": \"null\", \"orgs\": \"null\", \"orgs_zh\": \"null\", \"sid\": \"null\"}]\n\n# add_resolved_names(authors)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"67ef8d28-485a-4b73-9583-acd5e0a7886a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# publ titles\nimport requests\n\ndef resolve_title(title):\n    response = requests.get(\"https://dblp.org/search/publ/api\", params={\"q\": title, \"format\": \"json\"})\n    if response.status_code == 200:\n        result = response.json()\n        if \"result\" in result and \"hits\" in result[\"result\"]:\n            for hit in result[\"result\"][\"hits\"][\"hit\"]:\n                if \"info\" in hit and \"title\" in hit[\"info\"]:\n                    title_name = hit[\"info\"][\"title\"]\n#                     if title_name.lower() == title.lower():\n                    return title_name\n    return title\n\n# resolve_title('A stepwise framework for the normalization of array CGH data.')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"813745f3-fcbd-4d71-979b-9c9bc06d9477","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import explode, desc, row_number\nfrom pyspark.sql.window import Window\n\n\n# Function to merge two schemas\ndef merge_schemas(schema1, schema2):\n    merged_fields = {field.name: field for field in schema1}\n    for field in schema2:\n        if field.name not in merged_fields:\n            merged_fields[field.name] = field\n    return StructType(sorted(merged_fields.values(), key=lambda field: field.name))\n\n  \ndef preprocess_dataframe(df):\n    df = df.dropDuplicates()\n    \n    # 1. Drop publications with very short titles (one word, empty authors, etc.)\n    df = df.filter(df.title.isNotNull()) \\\n        .filter(length(df.title) > 5) \\\n        .filter(col('title').contains(' '))\\\n        .filter(~df.title.rlike(\".*Editorial.*\")) \\\n        .filter(~df.title.rlike(\".*Forward.*\")) \\\n        .filter(~df.title.rlike(\".*Preface.*\")) \\\n        .filter(~df.title.rlike(\".*Conference.*\")) \\\n        .filter(~df.title.rlike(\".*Proceedings.*\")) \\\n        .filter(~df.title.rlike(\".*Symposium.*\")) \\\n        .filter(~df.title.rlike(\".*Workshop.*\")) \\\n        .filter(~df.title.rlike(\".*Tutorial.*\")) \\\n        .filter(~df.title.rlike(\".*Forum.*\"))\n\n    df = df.filter(length(df.abstract) > 0)\n\n    df = df.filter(df.issn.isNotNull()) \\\n        .filter(length(df.issn) > 5)\n    \n    # 3. ISSN is sometimes filled with wrong values, we can either drop or make an effor to resolve using DOI for instance.\n    df = df.filter(~df.doi.rlike(\".*[a-zA-Z]+.*\"))\n    \n    \n    # 4. Defining the type of publication (journal, book, conference, etc.)\n    # Create a new column with the default publication type of 'Conference'\n    df = df.withColumn('pub_type', lit('Conference'))\n    # Update the publication type based on the 'venue.raw', 'volume', and 'issue' columns\n    df = df.withColumn('pub_type', when(col('venue.raw').contains('@'), 'Workshop')\n                                   .when((col('volume') != '') | (col('issue') != ''), 'Journal')\n                                   .otherwise(col('pub_type')))\n    \n    # 5. Resolving ambiguous author names\n    resolve_name_udf = udf(add_resolved_names, StringType())\n    df = df.withColumn(\"resolved_authors\", resolve_name_udf(df.authors))\n    \n    # 6. Resolving ambiguous or abbreviated conference and journal names using DBLP database\n    resolve_title_udf = udf(resolve_title, StringType())\n    df = df.withColumn(\"resolved_title\", resolve_title_udf(df.title))\n    \n    # 8. Author gender\n#     get_author_gender_udf = udf(add_author_gender, StringType())\n#     df = df.withColumn('authors_gender', get_author_gender_udf(df.resolved_authors))\n    \n    \n    # 9.\n    \n\n    \n    # 10. \n    \n\n\n    return df\n"],"metadata":{"ExecuteTime":{"end_time":"2023-04-20T19:02:46.250861700Z","start_time":"2023-04-20T19:02:46.200145900Z"},"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3588f0d7-2ff8-4ded-9f99-ca0d29296b3c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# We read JSON files with schema inference and preprocess them\njson_files = [f\"{path_to_data}{i}.json\" for i in range(1,2)]\ndataframes = [preprocess_dataframe(spark.read.option(\"inferSchema\", \"true\").json(file)) for file in json_files]"],"metadata":{"ExecuteTime":{"end_time":"2023-04-20T19:08:41.339930500Z","start_time":"2023-04-20T19:03:29.886291Z"},"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"16c0fa4b-be60-4487-a105-3f55f9943667","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# for test\n# for df in dataframes[]:\n#     display(df)\ndisplay(dataframes[0].limit(5))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b902342c-7449-4e98-b1b8-553355984738","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Merge schemas from all dataframes\nmerged_schema = dataframes[0].schema\nfor df in dataframes[1:]:\n    merged_schema = merge_schemas(merged_schema, df.schema)\n\n# Apply the merged schema to all dataframes\ndataframes_with_merged_schema = [df.selectExpr(*merged_schema.fieldNames()) for df in dataframes]\n\n# Union all dataframes to create a single dataframe with a consistent schema\ncombined_df = dataframes_with_merged_schema[0]\nfor df in dataframes_with_merged_schema[1:]:\n    combined_df = combined_df.unionByName(df, allowMissingColumns=True)\n\n# Save the combined dataframe to a Delta table\ncombined_df.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").save(\"dbfs:/FileStore/tables/delta/dblpv13\")"],"metadata":{"ExecuteTime":{"end_time":"2023-04-20T19:21:29.706537400Z","start_time":"2023-04-20T19:14:37.246656600Z"},"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c0e2f9ff-f989-4e47-bd86-e545dfdd6ab9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["combined_df = combined_df.withColumn(\"publication_id\", monotonically_increasing_id()) \\\n    .withColumn(\"author_id\", monotonically_increasing_id()) \\\n    .withColumn(\"venue_id\", monotonically_increasing_id()) \\\n    .withColumn(\"fos_id\", monotonically_increasing_id()) \\\n    .withColumn(\"org_id\", monotonically_increasing_id()) \\\n    .withColumn(\"date_id\", monotonically_increasing_id()) \\\n    .withColumn(\"keyword_id\", monotonically_increasing_id()) \\\n    .withColumn(\"type_id\", monotonically_increasing_id()) \\\n    .withColumn(\"lang_id\", monotonically_increasing_id())\n\n# display(combined_df)\n\ndblp_fact_table = combined_df.select(\"date_id\", \"keyword_id\", \"type_id\", \"publication_id\", \"venue_id\",\n                                      \"fos_id\", \"org_id\", \"author_id\", \"lang_id\")\n\nkeyword_table = combined_df.select(\"keyword_id\",\n                                   col(\"keywords\").alias(\"text\"))\n\n\nvenue_table = combined_df.select(\"venue_id\",\n                                 col(\"venue.name_d\").alias(\"name\"),\n                                 col(\"venue.type\").alias(\"type\"),\n                                 col(\"venue.raw\").alias(\"raw\"),\n                                 col(\"venue._id\").alias(\"vid\"))\n\ndate_table = combined_df.select(\"date_id\",\n                                year(\"year\").alias(\"year\"))\n\nlanguage_table = combined_df.select(\"lang_id\",\n                                    col(\"lang\").alias(\"name\"))\n\n\nfos_table = combined_df.select(\"fos_id\",\n                               col(\"fos\").alias(\"field\"))\n\nauthor_table = combined_df.select(\"author_id\",\n                                  col(\"authors.name\").alias(\"name\"),\n                                  col(\"authors.org\").alias(\"org\"),\n                                  col(\"authors.gid\").alias(\"gid\"),\n                                  col(\"authors.orgid\").alias(\"orgid\"),\n                                  col(\"authors_gender\").alias(\"gender\"))\n\npublication_table = combined_df.select(\"publication_id\",\n#                                        col(\"title\").alias(\"name\"),\n                                       col(\"resolved_title\").alias(\"name\"),\n                                       col(\"abstract\").alias(\"description\"),\n                                       col(\"doi\").alias(\"doi\"),\n                                       col(\"issn\").alias(\"issn\"),\n                                       col(\"isbn\").alias(\"isbn\"),\n                                       col(\"url\").alias(\"url\"),\n                                       col(\"pdf\").alias(\"pdf\"),\n                                       col(\"page_start\").alias(\"page_start\"),\n                                       col(\"page_end\").alias(\"page_end\"),\n                                       col(\"volume\").alias(\"volume\"),\n                                       col(\"issue\").alias(\"issue\"),\n                                       col(\"n_citation\").alias(\"n_citation\"),\n                                       col(\"pub_type\").alias(\"pub_type\"))\n"],"metadata":{"ExecuteTime":{"end_time":"2023-04-20T19:48:17.861229300Z","start_time":"2023-04-20T19:48:16.856601500Z"},"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f8220325-0e7d-4c0b-8e78-2200aeda877e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["dblp_fact_table.write.format(\"delta\").mode(\"append\").save(\"dbfs:/FileStore/tables/delta/dblp_fact_table\")\nkeyword_table.write.format(\"delta\").mode(\"append\").save(\"dbfs:/FileStore/tables/delta/keyword_table\")\nvenue_table.write.format(\"delta\").mode(\"append\").save(\"dbfs:/FileStore/tables/delta/venue_table\")\ndate_table.write.format(\"delta\").mode(\"append\").save(\"dbfs:/FileStore/tables/delta/date_table\")\nlanguage_table.write.format(\"delta\").mode(\"append\").save(\"dbfs:/FileStore/tables/delta/language_table\")\nfos_table.write.format(\"delta\").mode(\"append\").save(\"dbfs:/FileStore/tables/delta/fos_table\")\nauthor_table.write.format(\"delta\").mode(\"append\").save(\"dbfs:/FileStore/tables/delta/author_table\")\npublication_table.write.format(\"delta\").mode(\"append\").save(\"dbfs:/FileStore/tables/delta/publication_table\")\n"],"metadata":{"ExecuteTime":{"end_time":"2023-04-20T20:48:38.190760300Z","start_time":"2023-04-20T19:48:52.811099300Z"},"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0077d25d-b3f6-46b9-a537-f9b13fc07587","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["# load table from delta lake\nauthor_table = spark.read.format(\"delta\").load(\"dbfs:/FileStore/tables/delta/author_table\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"26f45324-17bc-4809-b67c-001c67cfe11c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["# dbutils.fs.rm(\"dbfs:/FileStore/tables/delta/author_table\", recurse=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0140c937-d22f-4d08-92bc-68055fcd520a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["display(author_table)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"8edd1d01-2957-4b7d-aa7b-06b3ca5ba095","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.9","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"ETL_Pipeline","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":3852023357860461,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
